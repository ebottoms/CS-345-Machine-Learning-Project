{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "The dataset we are using is comprised of 2.5 years of insulin dosage, blood glucose (bg), and Estimated Variability of Glucose (EVG). This data was collected from a type 1 diabetic's insulin pump and continuous glucose monitor (CGM). Unfortunately this data isnt entirely continous over the 2.5 year span and has gaps in some instances. This data has been exported directly from 30 day span .csv files containing 3 tables one for insulin dosage (bolus), bg, and EVG data. We split these files into the 3 respective tables and saved them to new tables containing the full time-span of data, these files are titles Bolus.csv, BG.csv, and EVG.csv. Here I will detail the contents of these files.\n",
    "\n",
    "1. Bolus\n",
    "    * Features:\n",
    "        * Type: Type of bolus event (Always 'Bolus').\n",
    "        * BolusType: Describes the wayin which the Bolus was used (categorical).\n",
    "        * BolusDeliveryMethod: Method used to deliver the bolus (Auto or Standard)(categorical).\n",
    "        * BG (mg/dL): Blood glucose levels at the time of bolus administration (continuous data).\n",
    "        * SerialNumber: Device identifier.\n",
    "        * CompletionDateTime: Timestamp when the dosing was completed.\n",
    "        * InsulinDelivered: The standard unit measure for the amount of insulin delivered (continuous data).\n",
    "        * FoodDelivered: Insulin delivered for food consumption (continuous data).\n",
    "        * CorrectionDelivered: Insulin delivered for BG correction (continuous data).\n",
    "        * CompletionStatusDesc: Status description of the dosage (categorical).\n",
    "        * BolexStartDateTime: Not Used In Export.\n",
    "        * BolexCompletionDateTime: Not Used In Export.\n",
    "        * BolexInsulinDelivered: Not Used In Export.\n",
    "        * BolexCompletionStatusDesc: Not Used In Export.\n",
    "        * StandardPercent: (Always 100).\n",
    "        * Duration (mins):(Always 0).\n",
    "        * CarbSize: The amount of carbohydrates consumed in grams (continuous data).\n",
    "        * TargetBG (mg/dL): Target blood glucose level for the subject in milligrams per deciliter (continuous data).\n",
    "        * CorrectionFactor: Insulin sensitivity factor (continuous data).\n",
    "        * CarbRatio: Insulin-to-carbohydrate ratio (continuous data).\n",
    "    * Notes:\n",
    "        * This table holds the most detailed records for insulin dosing decisions, food intake, and blood glucose corrections.\n",
    "        * This table will be very useful in modeling relationships between carbohydrate intake, insulin dosage, and BG levels.\n",
    "        * Bolus (Def: A large single doseage of insuline to lower a bloodsugar rise) refers to the device/method of insuline delivery. Which is automated through a pocket size device with a refillable tank of insulin.\n",
    "2. EVG Table\n",
    "    * Features:\n",
    "        * DeviceType: Type/Name of the device used to record the event.\n",
    "        * SerialNumber: Device identifier.\n",
    "        * Description: A text description of the type of data recorded (Always EVG).\n",
    "        * EventDateTime: Timestamp of when the measurement was recorded.\n",
    "        * Readings (mg/dL): The estimated glucose level at the recorded time, in milligrams per deciliter (mg/dL).\n",
    "    * Notes: \n",
    "        * The EVG data is collected directly from a CGM.\n",
    "        * EVG is designed for tracking overall trends and patterns in glucose levels rather than moment-to-moment decisions.\n",
    "        * Useful for identifying time-in-range, glucose variability, and predicting hypo/hyperglycemia over time.\n",
    "        \n",
    "3. BG Table\n",
    "    * Features:\n",
    "        * DeviceType: Type/Name of device used to measure blood glucose.\n",
    "        * SerialNumber: Device identifier.\n",
    "        * Description: A text description of the type of data recorded (Always BG)\n",
    "        * EventDateTime: Timestamp of the blood glucose measurement.\n",
    "        * BG (mg/dL): Blood glucose levels in milligrams per deciliter (continuous data).\n",
    "        * Note: Additional notes field (Always Blank).\n",
    "    * Notes:\n",
    "        * This data is manually entered and is recorded through a glucometer (Finger Prick).\n",
    "        * The BG measurement reflects the actual glucose levels at the time of measurement.\n",
    "\n",
    "\n",
    "### General Dataset Properties\n",
    "\n",
    "* Total \\# of Features:\n",
    "    * Bolus: 18 features\n",
    "    * EVG: 5 features\n",
    "    * BG: 6 features\n",
    "* \\# of Usable/Useful Features: (!!!!! Update possibly)\n",
    "    * Bolus: 12 features\n",
    "    * EVG: 2 features\n",
    "    * BG: 2 features\n",
    "* Table Sizes:\n",
    "    * Bolus: 11,348 Records\n",
    "    * EVG: 191,781 Records\n",
    "    * BG: 2,832 Records\n",
    "* Unique Dates: \n",
    "    * Bolus: 599 Days\n",
    "    * EVG: 666 Days\n",
    "    * BG: 663 Days\n",
    "* Intersecting Dates: 599\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Notes\n",
    "* Not all Days are covered, at points there are significant (5-8 week) gaps in data.\n",
    "* Different Devices used to collect data may overlap times (device marked as 'UNKNOWN' in data)\n",
    "* 3 different tables (I think our main focus should be on the third table that has the pump data coupled with the best of the BG tables (1 or 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Table 1 DataFrame:\n",
      "  DeviceType SerialNumber Description        EventDateTime Readings (mg/dL)\n",
      "0    Unknown       870772         EGV  2023-03-01T00:00:55              174\n",
      "1    Unknown       870772         EGV  2023-03-01T00:05:55              172\n",
      "2    Unknown       870772         EGV  2023-03-01T00:10:55              171\n",
      "3    Unknown       870772         EGV  2023-03-01T00:15:55              168\n",
      "4    Unknown       870772         EGV  2023-03-01T00:20:55              165\n",
      "\n",
      "Table 2 DataFrame:\n",
      "  DeviceType SerialNumber Description        EventDateTime BG (mg/dL) Note\n",
      "0    Unknown       870772          BG  2023-03-01T16:07:59        238     \n",
      "1    Unknown       870772          BG  2023-03-01T18:04:52        382     \n",
      "2    Unknown       870772          BG  2023-03-01T20:09:14        156     \n",
      "3    Unknown       870772          BG  2023-03-01T20:31:14        248     \n",
      "4    Unknown       870772          BG  2023-03-02T12:46:15        157     \n",
      "\n",
      "Table 3 DataFrame:\n",
      "    Type BolusType BolusDeliveryMethod BG (mg/dL) SerialNumber  \\\n",
      "0  Bolus      Auto                Auto          0       870772   \n",
      "1  Bolus      Auto                Auto          0       870772   \n",
      "2  Bolus      Auto                Auto          0       870772   \n",
      "3  Bolus      Auto                Auto          0       870772   \n",
      "4  Bolus      Auto                Auto          0       870772   \n",
      "\n",
      "    CompletionDateTime InsulinDelivered FoodDelivered CorrectionDelivered  \\\n",
      "0  2023-03-01T01:02:24             0.65             0                   0   \n",
      "1  2023-03-01T02:12:13             1.24             0                   0   \n",
      "2  2023-03-01T03:22:44             0.64             0                   0   \n",
      "3  2023-03-01T07:48:06             0.62             0                   0   \n",
      "4  2023-03-01T08:53:18             1.01             0                   0   \n",
      "\n",
      "  CompletionStatusDesc BolexStartDateTime BolexCompletionDateTime  \\\n",
      "0            Completed                                              \n",
      "1            Completed                                              \n",
      "2            Completed                                              \n",
      "3            Completed                                              \n",
      "4            Completed                                              \n",
      "\n",
      "  BolexInsulinDelivered BolexCompletionStatusDesc StandardPercent  \\\n",
      "0                                                             100   \n",
      "1                                                             100   \n",
      "2                                                             100   \n",
      "3                                                             100   \n",
      "4                                                             100   \n",
      "\n",
      "  Duration (mins) CarbSize TargetBG (mg/dL) CorrectionFactor CarbRatio  \n",
      "0               0        0              110               65       0.0  \n",
      "1               0        0              110               65       0.0  \n",
      "2               0        0              110               65       0.0  \n",
      "3               0        0              110               65       0.0  \n",
      "4               0        0              110               65       0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "def load_export_csv(file_path):\n",
    "    # Define the headers for each table to identify them\n",
    "    table_headers = {\n",
    "        'table1': [\"DeviceType\", \"SerialNumber\", \"Description\", \"EventDateTime\", \"Readings (mg/dL)\"],\n",
    "        'table2': [\"DeviceType\", \"SerialNumber\", \"Description\", \"EventDateTime\", \"BG (mg/dL)\", \"Note\"],\n",
    "        'table3': [\"Type\", \"BolusType\", \"BolusDeliveryMethod\", \"BG (mg/dL)\", \"SerialNumber\",\n",
    "                   \"CompletionDateTime\", \"InsulinDelivered\", \"FoodDelivered\", \"CorrectionDelivered\",\n",
    "                   \"CompletionStatusDesc\", \"BolexStartDateTime\", \"BolexCompletionDateTime\",\n",
    "                   \"BolexInsulinDelivered\", \"BolexCompletionStatusDesc\", \"StandardPercent\",\n",
    "                   \"Duration (mins)\", \"CarbSize\", \"TargetBG (mg/dL)\", \"CorrectionFactor\",\n",
    "                   \"CarbRatio\"]\n",
    "    }\n",
    "    \n",
    "    # Initialize data storage for each table\n",
    "    data_tables = {\n",
    "        'table1': [],\n",
    "        'table2': [],\n",
    "        'table3': []\n",
    "    }\n",
    "    \n",
    "    current_table = None  # To keep track of which table we're currently reading\n",
    "    line_number = 0  # To track line numbers for debugging\n",
    "    \n",
    "    with open(file_path, 'r', newline='', encoding='utf-8-sig') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            line_number += 1\n",
    "            # Strip whitespace from each cell\n",
    "            row = [cell.strip() for cell in row]\n",
    "            \n",
    "            # Debugging: Print current row and line number\n",
    "            # print(f\"Line {line_number}: {row}\")\n",
    "            \n",
    "            # Check if the row matches any table header\n",
    "            if row[:len(table_headers['table1'])] == table_headers['table1']:\n",
    "                current_table = 'table1'\n",
    "                # print(f\"Detected header for table1 at line {line_number}\")\n",
    "                continue  # Skip the header row\n",
    "            elif row[:len(table_headers['table2'])] == table_headers['table2']:\n",
    "                current_table = 'table2'\n",
    "                # print(f\"Detected header for table2 at line {line_number}\")\n",
    "                continue  # Skip the header row\n",
    "            elif row[:len(table_headers['table3'])] == table_headers['table3']:\n",
    "                current_table = 'table3'\n",
    "                # print(f\"Detected header for table3 at line {line_number}\")\n",
    "                continue  # Skip the header row\n",
    "            elif not any(cell for cell in row):\n",
    "                # Empty row signifies possible separation; skip\n",
    "                current_table = None\n",
    "                # print(f\"Detected empty row at line {line_number}; resetting current_table\")\n",
    "                continue\n",
    "            \n",
    "            # If current_table is set, append the row to the corresponding data list\n",
    "            if current_table:\n",
    "                expected_columns = len(table_headers[current_table])\n",
    "                actual_columns = len(row)\n",
    "                \n",
    "                if actual_columns != expected_columns:\n",
    "                    print(f\"Warning: Line {line_number} has {actual_columns} columns, expected {expected_columns}. Skipping row.\")\n",
    "                    continue  # Skip rows that don't match the expected column count\n",
    "                \n",
    "                # Replace '(Data)' placeholders with actual data if necessary\n",
    "                cleaned_row = [cell if cell != '(Data)' else None for cell in row]\n",
    "                data_tables[current_table].append(cleaned_row)\n",
    "            else:\n",
    "                # Rows outside of any table headers are ignored\n",
    "                print(f\"Warning: Line {line_number} is outside of any table. Skipping row.\")\n",
    "                continue\n",
    "    \n",
    "    # Convert lists to DataFrames with appropriate columns\n",
    "    df_tables = {}\n",
    "    for table_key, data in data_tables.items():\n",
    "        if data:  # Only create DataFrame if there's data\n",
    "            df = pd.DataFrame(data, columns=table_headers[table_key])\n",
    "            df_tables[table_key] = df\n",
    "        else:\n",
    "            df_tables[table_key] = pd.DataFrame(columns=table_headers[table_key])\n",
    "    \n",
    "    return df_tables['table1'], df_tables['table2'], df_tables['table3']\n",
    "\n",
    "\n",
    "\n",
    "file_path = './Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1920-2.csv'  \n",
    "df_table1, df_table2, df_table3 = load_export_csv(file_path)\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"Table 1 DataFrame:\")\n",
    "print(df_table1.head())\n",
    "\n",
    "print(\"\\nTable 2 DataFrame:\")\n",
    "print(df_table2.head())\n",
    "\n",
    "print(\"\\nTable 3 DataFrame:\")\n",
    "print(df_table3.head())\n",
    "\n",
    "# Optionally, save the DataFrames to separate CSV files\n",
    "df_table1.to_csv(os.path.join('./DataTables', 'table_1.csv'), index=False)\n",
    "df_table2.to_csv(os.path.join('./DataTables', 'table_2.csv'), index=False)\n",
    "df_table3.to_csv(os.path.join('./DataTables', 'table_3.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/2022PumpData\n",
      "./Data/2023PumpData\n",
      "./Data/2024PumpData\n",
      "./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1917-2.csv\n",
      "./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1910.csv\n",
      "./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1912.csv\n",
      "./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1916-2.csv\n",
      "./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1917.csv\n",
      "./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1916.csv\n",
      "./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1914.csv\n",
      "./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1918.csv\n",
      "./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1908.csv\n",
      "./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1924.csv\n",
      "./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1918.csv\n",
      "./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1923-2.csv\n",
      "./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1922.csv\n",
      "./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1923.csv\n",
      "./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1921-3.csv\n",
      "./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1921.csv\n",
      "./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1920.csv\n",
      "./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1921-2.csv\n",
      "./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1924-2.csv\n",
      "./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1924-3.csv\n",
      "./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1920-2.csv\n",
      "./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1922-2.csv\n",
      "./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1859.csv\n",
      "./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1858.csv\n",
      "./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1900.csv\n",
      "./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1901.csv\n",
      "./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1901-3.csv\n",
      "./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1901-2.csv\n",
      "./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1859-2.csv\n",
      "./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1857.csv\n",
      "./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1858-2.csv\n",
      "./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1900-2.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def gather_csv_files(main_directory):\n",
    "    \"\"\"\n",
    "    Gathers all CSV files from subdirectories (2022PumpData, 2023PumpData, 2024PumpData)\n",
    "    in the 'data' directory located in the main directory.\n",
    "\n",
    "    Parameters:\n",
    "        main_directory (str): The path to the main directory.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of paths to all CSV files found in the specified subdirectories.\n",
    "    \"\"\"\n",
    "    # Define the parent directory\n",
    "    parent_directory = os.path.join(main_directory, 'Data')\n",
    "    \n",
    "    # List of subdirectories to search\n",
    "    subdirectories = ['2022PumpData', '2023PumpData', '2024PumpData']\n",
    "    \n",
    "    # Collect CSV files from all subdirectories\n",
    "    csv_files = []\n",
    "    for subdir in subdirectories:\n",
    "        subdir_path = os.path.join(parent_directory, subdir)\n",
    "        print(subdir_path)\n",
    "        csv_files.extend(glob.glob(os.path.join(subdir_path, '*.csv')))\n",
    "    \n",
    "    return csv_files\n",
    "\n",
    "# Usage example\n",
    "main_directory = './'  # Replace with the path to your main directory\n",
    "csv_files = gather_csv_files(main_directory)\n",
    "\n",
    "# Print the gathered CSV file paths\n",
    "for file in csv_files:\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Data/2022PumpData\n",
      "./Data/2023PumpData\n",
      "./Data/2024PumpData\n",
      "Processing file: ./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1917-2.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1910.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1912.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1916-2.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1917.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1916.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1914.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1918.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2022PumpData/CSV_redacted_90945369_02Dec2024_1908.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1924.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1918.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1923-2.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1922.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1923.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1921-3.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1921.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1920.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1921-2.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1924-2.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1924-3.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1920-2.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2023PumpData/CSV_redacted_90945369_02Dec2024_1922-2.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1859.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1858.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1900.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1901.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1901-3.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1901-2.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1859-2.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1857.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1858-2.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Processing file: ./Data/2024PumpData/CSV_redacted_90945369_02Dec2024_1900-2.csv\n",
      "Warning: Line 1 is outside of any table. Skipping row.\n",
      "Warning: Line 2 is outside of any table. Skipping row.\n",
      "Warning: Line 3 is outside of any table. Skipping row.\n",
      "Warning: Line 4 is outside of any table. Skipping row.\n",
      "Warning: Line 5 is outside of any table. Skipping row.\n",
      "Combined tables saved to: ./DataTables\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_all_csv_files_combined(main_directory, output_directory):\n",
    "    \"\"\"\n",
    "    Processes all CSV files in the 'Data/2022PumpData', 'Data/2023PumpData', and 'Data/2024PumpData'\n",
    "    subdirectories, extracting tables and appending them into combined CSV files.\n",
    "\n",
    "    Parameters:\n",
    "        main_directory (str): The path to the main directory containing the 'Data' folder.\n",
    "        output_directory (str): The path to the directory where combined tables will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Gather all CSV files\n",
    "    csv_files = gather_csv_files(main_directory)\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Initialize empty DataFrames for combined output\n",
    "    combined_table1 = pd.DataFrame()\n",
    "    combined_table2 = pd.DataFrame()\n",
    "    combined_table3 = pd.DataFrame()\n",
    "\n",
    "    for file_path in csv_files:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Load the CSV file and extract tables\n",
    "            df_table1, df_table2, df_table3 = load_export_csv(file_path)\n",
    "            \n",
    "            # Append each table to its respective combined DataFrame\n",
    "            combined_table1 = pd.concat([combined_table1, df_table1], ignore_index=True)\n",
    "            combined_table2 = pd.concat([combined_table2, df_table2], ignore_index=True)\n",
    "            combined_table3 = pd.concat([combined_table3, df_table3], ignore_index=True)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    # Define output file paths\n",
    "    table1_file = os.path.join(output_directory, 'EVG.csv')\n",
    "    table2_file = os.path.join(output_directory, 'BG.csv')\n",
    "    table3_file = os.path.join(output_directory, 'Bolus.csv')\n",
    "\n",
    "    # Save the combined tables to CSV\n",
    "    combined_table1.to_csv(table1_file, index=False)\n",
    "    combined_table2.to_csv(table2_file, index=False)\n",
    "    combined_table3.to_csv(table3_file, index=False)\n",
    "\n",
    "    print(f\"Combined tables saved to: {output_directory}\")\n",
    "\n",
    "\n",
    "# Usage example\n",
    "main_directory = './'  # Replace with the path to your main directory\n",
    "output_directory = './DataTables'  # Replace with your desired output directory\n",
    "\n",
    "process_all_csv_files_combined(main_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663\n",
      "Number of unique dates that intersect across all three tables: 599\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the CSV files into pandas DataFrames\n",
    "file_path1 = './DataTables/BG.csv'  # Replace with the actual path for Table 1\n",
    "file_path2 = './DataTables/EVG.csv'  # Replace with the actual path for Table 2\n",
    "file_path3 = './DataTables/Bolus.csv'  # Replace with the actual path for Table 3\n",
    "\n",
    "# Load the data\n",
    "df1 = pd.read_csv(file_path1)\n",
    "df2 = pd.read_csv(file_path2)\n",
    "df3 = pd.read_csv(file_path3)\n",
    "\n",
    "# Convert the EventDateTime column to datetime and extract dates\n",
    "df1['EventDate'] = pd.to_datetime(df1['EventDateTime']).dt.date\n",
    "df2['EventDate'] = pd.to_datetime(df2['EventDateTime']).dt.date\n",
    "df3['EventDate'] = pd.to_datetime(df3['CompletionDateTime']).dt.date\n",
    "\n",
    "# Find the unique dates for each table\n",
    "unique_dates1 = set(df1['EventDate'].unique())\n",
    "unique_dates2 = set(df2['EventDate'].unique())\n",
    "unique_dates3 = set(df3['EventDate'].unique())\n",
    "\n",
    "print(len(unique_dates3))\n",
    "\n",
    "# Find the intersection of unique dates across all three tables\n",
    "common_dates = unique_dates1.intersection(unique_dates2).intersection(unique_dates3)\n",
    "\n",
    "# Print the number of unique intersecting dates\n",
    "print(f\"Number of unique dates that intersect across all three tables: {len(common_dates)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
